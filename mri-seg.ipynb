{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":407317,"sourceType":"datasetVersion","datasetId":181273},{"sourceId":1299795,"sourceType":"datasetVersion","datasetId":751906}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport random\nimport glob\nimport PIL\nimport shutil\nimport numpy as np\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage import data\nfrom skimage.util import montage\nimport skimage.transform as skTrans\nfrom skimage.transform import rotate\nfrom skimage.transform import resize\nfrom PIL import Image, ImageOps\nimport nibabel as nib\nimport keras\nimport keras.backend as K\nfrom keras.callbacks import CSVLogger\nimport tensorflow as tf\nfrom tensorflow.keras.utils import plot_model\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\n#from tensorflow.keras.layers.experimental import preprocessing","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-11T12:09:20.061831Z","iopub.execute_input":"2024-10-11T12:09:20.062378Z","iopub.status.idle":"2024-10-11T12:09:34.701502Z","shell.execute_reply.started":"2024-10-11T12:09:20.062314Z","shell.execute_reply":"2024-10-11T12:09:34.700421Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"TRAIN_DATASET_PATH = \"/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/\"","metadata":{"execution":{"iopub.status.busy":"2024-10-11T12:09:34.703229Z","iopub.execute_input":"2024-10-11T12:09:34.703886Z","iopub.status.idle":"2024-10-11T12:09:34.708901Z","shell.execute_reply.started":"2024-10-11T12:09:34.703846Z","shell.execute_reply":"2024-10-11T12:09:34.707704Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"old_name = TRAIN_DATASET_PATH + \"BraTS20_Training_355/W39_1998.09.19_Segm.nii\"\nnew_name = TRAIN_DATASET_PATH + \"BraTS20_Training_355/BraTS20_Training_355_seg.nii\"\n\n# renaming the file\ntry:\n    os.rename(old_name, new_name)\n    print(\"File has been re-named successfully!\")\nexcept:\n    print(\"File is already renamed!\")","metadata":{"execution":{"iopub.status.busy":"2024-10-11T12:09:34.710216Z","iopub.execute_input":"2024-10-11T12:09:34.710623Z","iopub.status.idle":"2024-10-11T12:09:34.754627Z","shell.execute_reply.started":"2024-10-11T12:09:34.710579Z","shell.execute_reply":"2024-10-11T12:09:34.753526Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"File is already renamed!\n","output_type":"stream"}]},{"cell_type":"code","source":"scaler = MinMaxScaler()","metadata":{"execution":{"iopub.status.busy":"2024-10-11T12:09:34.757566Z","iopub.execute_input":"2024-10-11T12:09:34.758526Z","iopub.status.idle":"2024-10-11T12:09:34.762555Z","shell.execute_reply.started":"2024-10-11T12:09:34.758441Z","shell.execute_reply":"2024-10-11T12:09:34.761515Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# lists of directories with studies\ntrain_and_val_directories = [f.path for f in os.scandir(TRAIN_DATASET_PATH) if f.is_dir()]\n\ndef pathListIntoIds(dirList):\n    x = []\n    for i in range(0,len(dirList)):\n        x.append(dirList[i][dirList[i].rfind('/')+1:])\n    return x\n\ntrain_and_test_ids = pathListIntoIds(train_and_val_directories);\n\ntrain_test_ids, val_ids = train_test_split(train_and_test_ids,test_size=0.2)\ntrain_ids, test_ids = train_test_split(train_test_ids,test_size=0.15)","metadata":{"execution":{"iopub.status.busy":"2024-10-11T12:09:34.763915Z","iopub.execute_input":"2024-10-11T12:09:34.764261Z","iopub.status.idle":"2024-10-11T12:09:34.810747Z","shell.execute_reply.started":"2024-10-11T12:09:34.764225Z","shell.execute_reply":"2024-10-11T12:09:34.809874Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Define seg-areas\nSEGMENT_CLASSES = {\n    0 : 'NOT tumor',\n    1 : 'NECROTIC/CORE', # or NON-ENHANCING tumor CORE\n    2 : 'EDEMA',\n    3 : 'ENHANCING' # original 4 -> converted into 3\n}\n\n# Select Slices and Image Size\nVOLUME_SLICES = 100\nVOLUME_START_AT = 22 # first slice of volume that we will include\nIMG_SIZE=128","metadata":{"execution":{"iopub.status.busy":"2024-10-11T12:09:34.812226Z","iopub.execute_input":"2024-10-11T12:09:34.812605Z","iopub.status.idle":"2024-10-11T12:09:34.817947Z","shell.execute_reply.started":"2024-10-11T12:09:34.812567Z","shell.execute_reply":"2024-10-11T12:09:34.816974Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = 1, n_channels = 2, shuffle=True):\n        'Initialization'\n        self.dim = dim\n        self.batch_size = batch_size\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        Batch_ids = [self.list_IDs[k] for k in indexes]\n\n        # Generate data\n        X, y = self.__data_generation(Batch_ids)\n\n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, Batch_ids):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n        y = np.zeros((self.batch_size*VOLUME_SLICES, 240, 240))\n        Y = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, 4))\n\n\n        # Generate data\n        for c, i in enumerate(Batch_ids):\n            case_path = os.path.join(TRAIN_DATASET_PATH, i)\n\n            data_path = os.path.join(case_path, f'{i}_flair.nii');\n            flair = nib.load(data_path).get_fdata()\n\n            data_path = os.path.join(case_path, f'{i}_t1ce.nii');\n            t1ce = nib.load(data_path).get_fdata()\n\n            data_path = os.path.join(case_path, f'{i}_seg.nii');\n            seg = nib.load(data_path).get_fdata()\n\n            for j in range(VOLUME_SLICES):\n                 X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n                 X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(t1ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n\n                 y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT];\n\n        # Generate masks\n        y[y==4] = 3;\n        mask = tf.one_hot(y, 4);\n        Y = tf.image.resize(mask, (IMG_SIZE, IMG_SIZE));\n        return X/np.max(X), Y\n\ntraining_generator = DataGenerator(train_ids)\nvalid_generator = DataGenerator(val_ids)\ntest_generator = DataGenerator(test_ids)","metadata":{"execution":{"iopub.status.busy":"2024-10-11T12:09:34.819527Z","iopub.execute_input":"2024-10-11T12:09:34.819904Z","iopub.status.idle":"2024-10-11T12:09:34.837147Z","shell.execute_reply.started":"2024-10-11T12:09:34.819846Z","shell.execute_reply":"2024-10-11T12:09:34.836168Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# dice loss as defined above for 4 classes\ndef dice_coef(y_true, y_pred, smooth=1.0):\n    class_num = 4\n    for i in range(class_num):\n        y_true_f = K.flatten(y_true[:,:,:,i])\n        y_pred_f = K.flatten(y_pred[:,:,:,i])\n        intersection = K.sum(y_true_f * y_pred_f)\n        loss = ((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))\n        if i == 0:\n            total_loss = loss\n        else:\n            total_loss = total_loss + loss\n    total_loss = total_loss / class_num\n    return total_loss","metadata":{"execution":{"iopub.status.busy":"2024-10-11T12:09:34.838394Z","iopub.execute_input":"2024-10-11T12:09:34.838779Z","iopub.status.idle":"2024-10-11T12:09:34.851350Z","shell.execute_reply.started":"2024-10-11T12:09:34.838743Z","shell.execute_reply":"2024-10-11T12:09:34.850245Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Define per class evaluation of dice coef\ndef dice_coef_necrotic(y_true, y_pred, epsilon=1e-6):\n    intersection = K.sum(K.abs(y_true[:,:,:,1] * y_pred[:,:,:,1]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,1])) + K.sum(K.square(y_pred[:,:,:,1])) + epsilon)\n\ndef dice_coef_edema(y_true, y_pred, epsilon=1e-6):\n    intersection = K.sum(K.abs(y_true[:,:,:,2] * y_pred[:,:,:,2]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,2])) + K.sum(K.square(y_pred[:,:,:,2])) + epsilon)\n\ndef dice_coef_enhancing(y_true, y_pred, epsilon=1e-6):\n    intersection = K.sum(K.abs(y_true[:,:,:,3] * y_pred[:,:,:,3]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,3])) + K.sum(K.square(y_pred[:,:,:,3])) + epsilon)","metadata":{"execution":{"iopub.status.busy":"2024-10-11T12:09:34.852472Z","iopub.execute_input":"2024-10-11T12:09:34.852845Z","iopub.status.idle":"2024-10-11T12:09:34.862696Z","shell.execute_reply.started":"2024-10-11T12:09:34.852809Z","shell.execute_reply":"2024-10-11T12:09:34.861495Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Computing Precision\ndef precision(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + K.epsilon())\n        return precision\n\n\n# Computing Sensitivity\ndef sensitivity(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    return true_positives / (possible_positives + K.epsilon())\n\n\n# Computing Specificity\ndef specificity(y_true, y_pred):\n    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n    return true_negatives / (possible_negatives + K.epsilon())","metadata":{"execution":{"iopub.status.busy":"2024-10-11T12:09:34.866691Z","iopub.execute_input":"2024-10-11T12:09:34.867591Z","iopub.status.idle":"2024-10-11T12:09:34.877795Z","shell.execute_reply.started":"2024-10-11T12:09:34.867549Z","shell.execute_reply":"2024-10-11T12:09:34.876758Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def build_unet(inputs, ker_init, dropout):\n    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(inputs)\n    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv1)\n\n    pool = MaxPooling2D(pool_size=(2, 2))(conv1)\n    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool)\n    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool1)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv2)\n\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv3)\n\n\n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv3)\n    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool4)\n    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv5)\n    drop5 = Dropout(dropout)(conv5)\n\n    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(drop5))\n    merge7 = concatenate([conv3,up7], axis = 3)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge7)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv7)\n\n    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv7))\n    merge8 = concatenate([conv2,up8], axis = 3)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge8)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv8)\n\n    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv8))\n    merge9 = concatenate([conv,up9], axis = 3)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge9)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv9)\n\n    up = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv9))\n    merge = concatenate([conv1,up], axis = 3)\n    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge)\n    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n\n    conv10 = Conv2D(4, (1,1), activation = 'softmax')(conv)\n\n    return Model(inputs = inputs, outputs = conv10)","metadata":{"execution":{"iopub.status.busy":"2024-10-11T12:09:34.879430Z","iopub.execute_input":"2024-10-11T12:09:34.879831Z","iopub.status.idle":"2024-10-11T12:09:34.896700Z","shell.execute_reply.started":"2024-10-11T12:09:34.879788Z","shell.execute_reply":"2024-10-11T12:09:34.895527Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"input_layer = Input((IMG_SIZE, IMG_SIZE, 2))\n\nmodel = build_unet(input_layer, 'he_normal', 0.2)\n\nmodel.compile(loss=\"categorical_crossentropy\",\n              optimizer=keras.optimizers.Adam(learning_rate=0.001),\n              metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing])","metadata":{"execution":{"iopub.status.busy":"2024-10-11T12:09:34.898089Z","iopub.execute_input":"2024-10-11T12:09:34.898484Z","iopub.status.idle":"2024-10-11T12:09:35.320476Z","shell.execute_reply.started":"2024-10-11T12:09:34.898420Z","shell.execute_reply":"2024-10-11T12:09:35.319309Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import CSVLogger\n\ncallbacks = [\n    keras.callbacks.ReduceLROnPlateau(\n        monitor='val_loss', \n        factor=0.2,\n        patience=2, \n        min_lr=0.000001, \n        verbose=1\n    ),\n    keras.callbacks.ModelCheckpoint(\n        filepath='model_{epoch:02d}-{val_loss:.6f}.weights.h5',  # Updated extension\n        verbose=1, \n        save_best_only=True, \n        save_weights_only=True  # Keep this as True to save only weights\n    ),\n    CSVLogger('training.log', separator=',', append=False)\n]\n","metadata":{"execution":{"iopub.status.busy":"2024-10-11T12:09:35.321826Z","iopub.execute_input":"2024-10-11T12:09:35.322180Z","iopub.status.idle":"2024-10-11T12:09:35.328537Z","shell.execute_reply.started":"2024-10-11T12:09:35.322144Z","shell.execute_reply":"2024-10-11T12:09:35.327194Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\ndef dice_coef(y_true, y_pred, smooth=1e-6):\n    class_num = 4\n    dice = 0.0\n    for i in range(class_num):\n        y_true_f = tf.keras.backend.flatten(y_true[:, :, :, i])\n        y_pred_f = tf.keras.backend.flatten(y_pred[:, :, :, i])\n        intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n        dice += (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n    \n    return dice / class_num  # Average over the classes\n","metadata":{"execution":{"iopub.status.busy":"2024-10-11T12:09:35.330137Z","iopub.execute_input":"2024-10-11T12:09:35.330609Z","iopub.status.idle":"2024-10-11T12:09:35.339946Z","shell.execute_reply.started":"2024-10-11T12:09:35.330558Z","shell.execute_reply":"2024-10-11T12:09:35.338687Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nmodel.compile(optimizer='adam', \n              loss='categorical_crossentropy',  # Change to categorical_crossentropy\n              metrics=[dice_coef])\n","metadata":{"execution":{"iopub.status.busy":"2024-10-11T12:09:35.341285Z","iopub.execute_input":"2024-10-11T12:09:35.341686Z","iopub.status.idle":"2024-10-11T12:09:35.359982Z","shell.execute_reply.started":"2024-10-11T12:09:35.341613Z","shell.execute_reply":"2024-10-11T12:09:35.358867Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"K.clear_session()\n\nhistory =  model.fit(training_generator,\n                    epochs=35,\n                    steps_per_epoch=len(train_ids),\n                    callbacks= callbacks,\n                    validation_data = valid_generator\n                    )","metadata":{"execution":{"iopub.status.busy":"2024-10-11T12:09:35.361497Z","iopub.execute_input":"2024-10-11T12:09:35.362549Z","iopub.status.idle":"2024-10-11T12:26:06.168961Z","shell.execute_reply.started":"2024-10-11T12:09:35.362495Z","shell.execute_reply":"2024-10-11T12:26:06.166914Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch 1/35\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 40/250\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:25:01\u001b[0m 24s/step - dice_coef: 0.2043 - loss: 0.9701","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m K\u001b[38;5;241m.\u001b[39mclear_session()\n\u001b[0;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m  \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m35\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalid_generator\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nFileNotFoundError: No such file or no access: '/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_355/BraTS20_Training_355_seg.nii'\nTraceback (most recent call last):\n\n  File \"/opt/conda/lib/python3.10/site-packages/nibabel/loadsave.py\", line 100, in load\n    stat_result = os.stat(filename)\n\nFileNotFoundError: [Errno 2] No such file or directory: '/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_355/BraTS20_Training_355_seg.nii'\n\n\nDuring handling of the above exception, another exception occurred:\n\n\nTraceback (most recent call last):\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 260, in _get_iterator\n    for i, batch in enumerate(gen_fn()):\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 253, in generator_fn\n    yield self.py_dataset[i]\n\n  File \"/tmp/ipykernel_30/3405679555.py\", line 25, in __getitem__\n    X, y = self.__data_generation(Batch_ids)\n\n  File \"/tmp/ipykernel_30/3405679555.py\", line 54, in __data_generation\n    seg = nib.load(data_path).get_fdata()\n\n  File \"/opt/conda/lib/python3.10/site-packages/nibabel/loadsave.py\", line 102, in load\n    raise FileNotFoundError(f\"No such file or no access: '{filename}'\")\n\nFileNotFoundError: No such file or no access: '/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_355/BraTS20_Training_355_seg.nii'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_one_step_on_iterator_8937]"],"ename":"UnknownError","evalue":"Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nFileNotFoundError: No such file or no access: '/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_355/BraTS20_Training_355_seg.nii'\nTraceback (most recent call last):\n\n  File \"/opt/conda/lib/python3.10/site-packages/nibabel/loadsave.py\", line 100, in load\n    stat_result = os.stat(filename)\n\nFileNotFoundError: [Errno 2] No such file or directory: '/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_355/BraTS20_Training_355_seg.nii'\n\n\nDuring handling of the above exception, another exception occurred:\n\n\nTraceback (most recent call last):\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 260, in _get_iterator\n    for i, batch in enumerate(gen_fn()):\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 253, in generator_fn\n    yield self.py_dataset[i]\n\n  File \"/tmp/ipykernel_30/3405679555.py\", line 25, in __getitem__\n    X, y = self.__data_generation(Batch_ids)\n\n  File \"/tmp/ipykernel_30/3405679555.py\", line 54, in __data_generation\n    seg = nib.load(data_path).get_fdata()\n\n  File \"/opt/conda/lib/python3.10/site-packages/nibabel/loadsave.py\", line 102, in load\n    raise FileNotFoundError(f\"No such file or no access: '{filename}'\")\n\nFileNotFoundError: No such file or no access: '/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_355/BraTS20_Training_355_seg.nii'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_one_step_on_iterator_8937]","output_type":"error"}]},{"cell_type":"code","source":"model.save(\"my_model.keras\")","metadata":{"execution":{"iopub.status.busy":"2024-10-11T12:26:06.170163Z","iopub.status.idle":"2024-10-11T12:26:06.170632Z","shell.execute_reply.started":"2024-10-11T12:26:06.170404Z","shell.execute_reply":"2024-10-11T12:26:06.170428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = keras.models.load_model('/content/my_model.keras',\n                                   custom_objects={\"accuracy\" : tf.keras.metrics.MeanIoU(num_classes=4),\n                                                   \"dice_coef\" : dice_coef,\n                                                   \"precision\" : precision,\n                                                   \"sensitivity\" :sensitivity,\n                                                   \"specificity\" :specificity,\n                                                   \"dice_coef_necrotic\" : dice_coef_necrotic,\n                                                   \"dice_coef_edema\" : dice_coef_edema,\n                                                   \"dice_coef_enhancing\" : dice_coef_enhancing\n                                                  }, compile=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-11T12:26:06.172970Z","iopub.status.idle":"2024-10-11T12:26:06.173378Z","shell.execute_reply.started":"2024-10-11T12:26:06.173186Z","shell.execute_reply":"2024-10-11T12:26:06.173206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = pd.read_csv('/content/training.log', sep=',', engine='python')\n\nhist=history\n\nacc=hist['accuracy']\nval_acc=hist['val_accuracy']\n\nepoch=range(len(acc))\n\nloss=hist['loss']\nval_loss=hist['val_loss']\n\ntrain_dice=hist['dice_coef']\nval_dice=hist['val_dice_coef']\n\nf,ax=plt.subplots(1,4,figsize=(16,8))\n\nax[0].plot(epoch,acc,'b',label='Training Accuracy')\nax[0].plot(epoch,val_acc,'r',label='Validation Accuracy')\nax[0].legend()\n\nax[1].plot(epoch,loss,'b',label='Training Loss')\nax[1].plot(epoch,val_loss,'r',label='Validation Loss')\nax[1].legend()\n\nax[2].plot(epoch,train_dice,'b',label='Training dice coef')\nax[2].plot(epoch,val_dice,'r',label='Validation dice coef')\nax[2].legend()\n\nax[3].plot(epoch,hist['mean_io_u'],'b',label='Training mean IOU')\nax[3].plot(epoch,hist['val_mean_io_u'],'r',label='Validation mean IOU')\nax[3].legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-11T12:26:06.175613Z","iopub.status.idle":"2024-10-11T12:26:06.176075Z","shell.execute_reply.started":"2024-10-11T12:26:06.175868Z","shell.execute_reply":"2024-10-11T12:26:06.175888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile a model and load our saved weights\nIMG_SIZE = 128\ninput_layer = Input((IMG_SIZE, IMG_SIZE, 2))\n\nbest_saved_model = build_unet(input_layer, 'he_normal', 0.2)\n\nbest_saved_model.compile(loss=\"categorical_crossentropy\", optimizer=tensorflow.keras.optimizers.Adam(learning_rate=0.001), metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema, dice_coef_enhancing])\n\nbest_saved_model.load_weights('model_.19-0.021449.m5')","metadata":{"execution":{"iopub.status.busy":"2024-10-11T12:26:06.178350Z","iopub.status.idle":"2024-10-11T12:26:06.178837Z","shell.execute_reply.started":"2024-10-11T12:26:06.178584Z","shell.execute_reply":"2024-10-11T12:26:06.178606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def imageLoader(path):\n    image = nib.load(path).get_fdata()\n    X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n    for j in range(VOLUME_SLICES):\n        X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(image[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n        X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n\n        y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT];\n    return np.array(image)","metadata":{"execution":{"iopub.status.busy":"2024-10-11T12:26:06.181395Z","iopub.status.idle":"2024-10-11T12:26:06.181841Z","shell.execute_reply.started":"2024-10-11T12:26:06.181644Z","shell.execute_reply":"2024-10-11T12:26:06.181665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def loadDataFromDir(path, list_of_files, mriType, n_images):\n    scans = []\n    masks = []\n    for i in list_of_files[:n_images]:\n        fullPath = glob.glob( i + '/*'+ mriType +'*')[0]\n        currentScanVolume = imageLoader(fullPath)\n        currentMaskVolume = imageLoader( glob.glob( i + '/*seg*')[0] )\n        # for each slice in 3D volume, find also it's mask\n        for j in range(0, currentScanVolume.shape[2]):\n            scan_img = cv2.resize(currentScanVolume[:,:,j], dsize=(IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_AREA).astype('uint8')\n            mask_img = cv2.resize(currentMaskVolume[:,:,j], dsize=(IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_AREA).astype('uint8')\n            scans.append(scan_img[..., np.newaxis])\n            masks.append(mask_img[..., np.newaxis])\n    return np.array(scans, dtype='float32'), np.array(masks, dtype='float32')","metadata":{"execution":{"iopub.status.busy":"2024-10-11T12:26:06.183161Z","iopub.status.idle":"2024-10-11T12:26:06.183565Z","shell.execute_reply.started":"2024-10-11T12:26:06.183350Z","shell.execute_reply":"2024-10-11T12:26:06.183369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predictByPath(case_path,case):\n    files = next(os.walk(case_path))[2]\n    X = np.empty((VOLUME_SLICES, IMG_SIZE, IMG_SIZE, 2))\n\n    vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_flair.nii');\n    flair=nib.load(vol_path).get_fdata()\n\n    vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_t1ce.nii');\n    ce=nib.load(vol_path).get_fdata()\n\n\n    for j in range(VOLUME_SLICES):\n        X[j,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n        X[j,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n\n    return model.predict(X/np.max(X), verbose=1)","metadata":{"execution":{"iopub.status.busy":"2024-10-11T12:26:06.185005Z","iopub.status.idle":"2024-10-11T12:26:06.185577Z","shell.execute_reply.started":"2024-10-11T12:26:06.185268Z","shell.execute_reply":"2024-10-11T12:26:06.185297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def showPredictsById(case, start_slice = 60):\n    path = f\"/content/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_{case}\"\n    gt = nib.load(os.path.join(path, f'BraTS20_Training_{case}_seg.nii')).get_fdata()\n    origImage = nib.load(os.path.join(path, f'BraTS20_Training_{case}_flair.nii')).get_fdata()\n    p = predictByPath(path,case)\n\n    core = p[:,:,:,1]\n    edema= p[:,:,:,2]\n    enhancing = p[:,:,:,3]\n\n    plt.figure(figsize=(18, 50))\n    f, axarr = plt.subplots(1,6, figsize = (18, 50))\n\n    for i in range(6): # for each image, add brain background\n        axarr[i].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap=\"gray\", interpolation='none')\n\n    axarr[0].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap=\"gray\")\n    axarr[0].title.set_text('Original image flair')\n    curr_gt=cv2.resize(gt[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE), interpolation = cv2.INTER_NEAREST)\n    axarr[1].imshow(curr_gt, cmap=\"Reds\", interpolation='none', alpha=0.3) # ,alpha=0.3,cmap='Reds'\n    axarr[1].title.set_text('Ground truth')\n    axarr[2].imshow(p[start_slice,:,:,1:4], cmap=\"Reds\", interpolation='none', alpha=0.3)\n    axarr[2].title.set_text('all classes predicted')\n    axarr[3].imshow(edema[start_slice,:,:], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n    axarr[3].title.set_text(f'{SEGMENT_CLASSES[1]} predicted')\n    axarr[4].imshow(core[start_slice,:,], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n    axarr[4].title.set_text(f'{SEGMENT_CLASSES[2]} predicted')\n    axarr[5].imshow(enhancing[start_slice,:,], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n    axarr[5].title.set_text(f'{SEGMENT_CLASSES[3]} predicted')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-11T12:26:06.187566Z","iopub.status.idle":"2024-10-11T12:26:06.188049Z","shell.execute_reply.started":"2024-10-11T12:26:06.187818Z","shell.execute_reply":"2024-10-11T12:26:06.187838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_segmentation(sample_path):\n    # Load NIfTI (.nii) files of the sample (patient)\n    t1ce_path = sample_path + '_t1ce.nii'\n    flair_path = sample_path + '_flair.nii'\n\n    # Extract the data from these paths\n    t1ce = nib.load(t1ce_path).get_fdata()\n    flair = nib.load(flair_path).get_fdata()\n\n    # Create an empty array\n    X = np.empty((VOLUME_SLICES, IMG_SIZE, IMG_SIZE, 2))\n\n    # Perform the same operations as our DataGenerator, to keep the same input shape\n    for j in range(VOLUME_SLICES):\n        X[j,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n        X[j,:,:,1] = cv2.resize(t1ce[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n\n    # Send our images to the CNN model and return predicted segmentation\n    return model.predict(X/np.max(X), verbose=1)","metadata":{"execution":{"iopub.status.busy":"2024-10-11T12:26:06.189589Z","iopub.status.idle":"2024-10-11T12:26:06.190010Z","shell.execute_reply.started":"2024-10-11T12:26:06.189782Z","shell.execute_reply":"2024-10-11T12:26:06.189801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_predicted_segmentations(samples_list, slice_to_plot, cmap, norm):\n    # Choose a random patient\n    random_sample = random.choice(samples_list)\n\n    # Get path of this patient\n    random_sample_path = os.path.join(TRAIN_DATASET_PATH, random_sample, random_sample)\n\n    # Predict patient's segmentation\n    predicted_seg = predict_segmentation(random_sample_path)\n\n    # Load patient's original segmentation (Ground truth)\n    seg_path = random_sample_path + '_seg.nii'\n    seg = nib.load(seg_path).get_fdata()\n\n    # Resize original segmentation to the same dimensions of the predictions. (Add VOLUME_START_AT because original segmentation contains 155 slices vs only 75 for our prediction)\n    seg=cv2.resize(seg[:,:,slice_to_plot+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE), interpolation = cv2.INTER_NEAREST)\n\n    # Differentiate segmentations by their labels\n    all = predicted_seg[slice_to_plot,:,:,1:4] # Deletion of class 0 (Keep only Core + Edema + Enhancing classes)\n    zero = predicted_seg[slice_to_plot,:,:,0] # Isolation of class 0, Background (kind of useless, it is the opposite of the \"all\")\n    first = predicted_seg[slice_to_plot,:,:,1] # Isolation of class 1, Core\n    second = predicted_seg[slice_to_plot,:,:,2] # Isolation of class 2, Edema\n    third = predicted_seg[slice_to_plot,:,:,3] # Isolation of class 3, Enhancing\n\n    # Plot Original segmentation & predicted segmentation\n    print(\"Patient number: \", random_sample)\n    fig, axstest = plt.subplots(1, 6, figsize=(25, 20))\n\n    # Original segmentation\n    axstest[0].imshow(seg, cmap, norm)\n    axstest[0].set_title('Original Segmentation')\n\n    # Layers 1, 2, 3\n    axstest[1].imshow(all, cmap, norm)\n    axstest[1].set_title('Predicted Segmentation - all classes')\n\n    # Layer 0\n    axstest[2].imshow(zero)\n    axstest[2].set_title('Predicted Segmentation - Not Tumor')\n\n    # Layer 1\n    axstest[3].imshow(first)\n    axstest[3].set_title('Predicted Segmentation - Necrotic/Core')\n\n    # Layer 2\n    axstest[4].imshow(second)\n    axstest[4].set_title('Predicted Segmentation - Edema')\n\n    # Layer 3\n    axstest[5].imshow(third)\n    axstest[5].set_title('Predicted Segmentation - Enhancing')\n\n    # Add space between subplots\n    plt.subplots_adjust(wspace=0.8)\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-11T12:26:06.192638Z","iopub.status.idle":"2024-10-11T12:26:06.193192Z","shell.execute_reply.started":"2024-10-11T12:26:06.192893Z","shell.execute_reply":"2024-10-11T12:26:06.192919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_predicted_segmentations(test_ids, 60, cmap, norm)","metadata":{"execution":{"iopub.status.busy":"2024-10-11T12:26:06.194665Z","iopub.status.idle":"2024-10-11T12:26:06.195406Z","shell.execute_reply.started":"2024-10-11T12:26:06.195109Z","shell.execute_reply":"2024-10-11T12:26:06.195140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"case = test_ids[3][-3:]\npath = f\"/content/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_{case}\"\ngt = nib.load(os.path.join(path, f'BraTS20_Training_{case}_seg.nii')).get_fdata()\np = predictByPath(path,case)\n\ncore = p[:,:,:,1]\nedema= p[:,:,:,2]\nenhancing = p[:,:,:,3]\n\ni=40 # slice at\neval_class = 2 #     0 : 'NOT tumor',  1 : 'ENHANCING',    2 : 'CORE',    3 : 'WHOLE'\n\ngt[gt != eval_class] = 1 # use only one class for per class evaluation\n\nresized_gt = cv2.resize(gt[:,:,i+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))\n\nplt.figure()\nf, axarr = plt.subplots(1,2)\naxarr[0].imshow(resized_gt, cmap=\"gray\")\naxarr[0].title.set_text('ground truth')\naxarr[1].imshow(p[i,:,:,eval_class], cmap=\"gray\")\naxarr[1].title.set_text(f'predicted class: {SEGMENT_CLASSES[eval_class]}')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-11T12:26:06.197054Z","iopub.status.idle":"2024-10-11T12:26:06.197596Z","shell.execute_reply.started":"2024-10-11T12:26:06.197310Z","shell.execute_reply":"2024-10-11T12:26:06.197337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on the test data\nmodel.compile(loss=\"categorical_crossentropy\",\n              optimizer=keras.optimizers.Adam(learning_rate=0.001),\n              metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema, dice_coef_enhancing])\n\nresults = model.evaluate(test_generator, batch_size=100, callbacks= callbacks)\n\ndescriptions = [\"Loss\", \"Accuracy\", \"MeanIOU\", \"Dice coefficient\", \"Precision\", \"Sensitivity\", \"Specificity\", \"Dice coef Necrotic\", \"Dice coef Edema\", \"Dice coef Enhancing\"]\n\n# Combine results list and descriptions list\nresults_list = zip(results, descriptions)\n\n# Display each metric with its description\nprint(\"\\nModel evaluation on the test set:\")\nprint(\"==================================\")\nfor i, (metric, description) in enumerate(results_list):\n    print(f\"{description} : {round(metric, 4)}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-11T12:26:06.198971Z","iopub.status.idle":"2024-10-11T12:26:06.199368Z","shell.execute_reply.started":"2024-10-11T12:26:06.199172Z","shell.execute_reply":"2024-10-11T12:26:06.199192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}